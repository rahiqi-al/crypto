[2025-02-27T00:29:06.595+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-02-27T00:29:06.628+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: crypto.mapreduce scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T00:29:06.648+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: crypto.mapreduce scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T00:29:06.649+0000] {taskinstance.py:2867} INFO - Starting attempt 1 of 2
[2025-02-27T00:29:06.693+0000] {taskinstance.py:2890} INFO - Executing <Task(BashOperator): mapreduce> on 2025-02-26 00:00:00+00:00
[2025-02-27T00:29:06.699+0000] {standard_task_runner.py:72} INFO - Started process 3492674 to run task
[2025-02-27T00:29:06.704+0000] {standard_task_runner.py:104} INFO - Running: ['airflow', 'tasks', 'run', 'crypto', 'mapreduce', 'scheduled__2025-02-26T00:00:00+00:00', '--job-id', '40', '--raw', '--subdir', 'DAGS_FOLDER/crypto_dag.py', '--cfg-path', '/tmp/tmpiq58cj3o']
[2025-02-27T00:29:06.707+0000] {standard_task_runner.py:105} INFO - Job 40: Subtask mapreduce
[2025-02-27T00:29:06.766+0000] {task_command.py:467} INFO - Running <TaskInstance: crypto.mapreduce scheduled__2025-02-26T00:00:00+00:00 [running]> on host ali-ThinkBook-14-G2-ITL
[2025-02-27T00:29:07.062+0000] {taskinstance.py:3134} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='ali rahiqi' AIRFLOW_CTX_DAG_ID='crypto' AIRFLOW_CTX_TASK_ID='mapreduce' AIRFLOW_CTX_EXECUTION_DATE='2025-02-26T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-02-26T00:00:00+00:00'
[2025-02-27T00:29:07.063+0000] {taskinstance.py:732} INFO - ::endgroup::
[2025-02-27T00:29:07.084+0000] {subprocess.py:78} INFO - Tmp dir root location: /tmp
[2025-02-27T00:29:07.085+0000] {subprocess.py:88} INFO - Running command: ['/usr/bin/bash', '-c', '\n        hadoop jar /usr/local/hadoop/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar         -input /user/etudiant/crypto/raw/YYYY=2025/MM=02/DD=26/coingecko_raw.json         -output /user/etudiant/crypto/processed/YYYY=2025/MM=02/DD=26         -mapper /home/ali/Desktop/crypto/scripts/mapper.py         -reducer /home/ali/Desktop/crypto/scripts/reducer.py         -file /home/ali/Desktop/crypto/scripts/mapper.py         -file /home/ali/Desktop/crypto/scripts/reducer.py']
[2025-02-27T00:29:07.100+0000] {subprocess.py:99} INFO - Output:
[2025-02-27T00:29:08.297+0000] {subprocess.py:106} INFO - 2025-02-27 00:29:08,296 WARN streaming.StreamJob: -file option is deprecated, please use generic option -files instead.
[2025-02-27T00:29:09.681+0000] {subprocess.py:106} INFO - packageJobJar: [/home/ali/Desktop/crypto/scripts/mapper.py, /home/ali/Desktop/crypto/scripts/reducer.py, /tmp/hadoop-unjar413314459615167719/] [] /tmp/streamjob11019416603062201691.jar tmpDir=null
[2025-02-27T00:29:09.894+0000] {subprocess.py:106} INFO - 2025-02-27 00:29:09,894 INFO client.DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at /0.0.0.0:8032
[2025-02-27T00:29:10.181+0000] {subprocess.py:106} INFO - 2025-02-27 00:29:10,181 INFO client.DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at /0.0.0.0:8032
[2025-02-27T00:29:10.569+0000] {subprocess.py:106} INFO - 2025-02-27 00:29:10,569 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/ali/.staging/job_1740561960347_0011
[2025-02-27T00:29:11.114+0000] {subprocess.py:106} INFO - 2025-02-27 00:29:11,114 INFO mapred.FileInputFormat: Total input files to process : 1
[2025-02-27T00:29:11.185+0000] {subprocess.py:106} INFO - 2025-02-27 00:29:11,185 INFO mapreduce.JobSubmitter: number of splits:2
[2025-02-27T00:29:11.514+0000] {subprocess.py:106} INFO - 2025-02-27 00:29:11,514 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1740561960347_0011
[2025-02-27T00:29:11.515+0000] {subprocess.py:106} INFO - 2025-02-27 00:29:11,514 INFO mapreduce.JobSubmitter: Executing with tokens: []
[2025-02-27T00:29:11.803+0000] {subprocess.py:106} INFO - 2025-02-27 00:29:11,803 INFO conf.Configuration: resource-types.xml not found
[2025-02-27T00:29:11.804+0000] {subprocess.py:106} INFO - 2025-02-27 00:29:11,803 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.
[2025-02-27T00:29:11.899+0000] {subprocess.py:106} INFO - 2025-02-27 00:29:11,899 INFO impl.YarnClientImpl: Submitted application application_1740561960347_0011
[2025-02-27T00:29:11.960+0000] {subprocess.py:106} INFO - 2025-02-27 00:29:11,960 INFO mapreduce.Job: The url to track the job: http://ali-ThinkBook-14-G2-ITL:8088/proxy/application_1740561960347_0011/
[2025-02-27T00:29:11.962+0000] {subprocess.py:106} INFO - 2025-02-27 00:29:11,962 INFO mapreduce.Job: Running job: job_1740561960347_0011
[2025-02-27T00:29:21.127+0000] {subprocess.py:106} INFO - 2025-02-27 00:29:21,127 INFO mapreduce.Job: Job job_1740561960347_0011 running in uber mode : false
[2025-02-27T00:29:21.129+0000] {subprocess.py:106} INFO - 2025-02-27 00:29:21,128 INFO mapreduce.Job:  map 0% reduce 0%
[2025-02-27T00:29:28.317+0000] {subprocess.py:106} INFO - 2025-02-27 00:29:28,317 INFO mapreduce.Job: Task Id : attempt_1740561960347_0011_m_000001_0, Status : FAILED
[2025-02-27T00:29:28.354+0000] {subprocess.py:106} INFO - Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 2
[2025-02-27T00:29:28.355+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:326)
[2025-02-27T00:29:28.356+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:539)
[2025-02-27T00:29:28.356+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.streaming.PipeMapper.close(PipeMapper.java:130)
[2025-02-27T00:29:28.357+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:61)
[2025-02-27T00:29:28.357+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
[2025-02-27T00:29:28.357+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:466)
[2025-02-27T00:29:28.358+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:350)
[2025-02-27T00:29:28.358+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:178)
[2025-02-27T00:29:28.359+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(Native Method)
[2025-02-27T00:29:28.359+0000] {subprocess.py:106} INFO - 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
[2025-02-27T00:29:28.360+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
[2025-02-27T00:29:28.360+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:172)
[2025-02-27T00:29:28.361+0000] {subprocess.py:106} INFO - 
[2025-02-27T00:29:28.361+0000] {subprocess.py:106} INFO - 2025-02-27 00:29:28,354 INFO mapreduce.Job: Task Id : attempt_1740561960347_0011_m_000000_0, Status : FAILED
[2025-02-27T00:29:28.362+0000] {subprocess.py:106} INFO - Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 2
[2025-02-27T00:29:28.362+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:326)
[2025-02-27T00:29:28.362+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:539)
[2025-02-27T00:29:28.363+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.streaming.PipeMapper.close(PipeMapper.java:130)
[2025-02-27T00:29:28.363+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:61)
[2025-02-27T00:29:28.364+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
[2025-02-27T00:29:28.364+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:466)
[2025-02-27T00:29:28.364+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:350)
[2025-02-27T00:29:28.365+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:178)
[2025-02-27T00:29:28.365+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(Native Method)
[2025-02-27T00:29:28.366+0000] {subprocess.py:106} INFO - 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
[2025-02-27T00:29:28.366+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
[2025-02-27T00:29:28.366+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:172)
[2025-02-27T00:29:28.367+0000] {subprocess.py:106} INFO - 
[2025-02-27T00:29:34.494+0000] {subprocess.py:106} INFO - 2025-02-27 00:29:34,493 INFO mapreduce.Job: Task Id : attempt_1740561960347_0011_m_000000_1, Status : FAILED
[2025-02-27T00:29:34.496+0000] {subprocess.py:106} INFO - Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 2
[2025-02-27T00:29:34.497+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:326)
[2025-02-27T00:29:34.497+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:539)
[2025-02-27T00:29:34.498+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.streaming.PipeMapper.close(PipeMapper.java:130)
[2025-02-27T00:29:34.498+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:61)
[2025-02-27T00:29:34.499+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
[2025-02-27T00:29:34.499+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:466)
[2025-02-27T00:29:34.499+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:350)
[2025-02-27T00:29:34.500+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:178)
[2025-02-27T00:29:34.500+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(Native Method)
[2025-02-27T00:29:34.500+0000] {subprocess.py:106} INFO - 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
[2025-02-27T00:29:34.501+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
[2025-02-27T00:29:34.501+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:172)
[2025-02-27T00:29:34.501+0000] {subprocess.py:106} INFO - 
[2025-02-27T00:29:34.502+0000] {subprocess.py:106} INFO - 2025-02-27 00:29:34,496 INFO mapreduce.Job: Task Id : attempt_1740561960347_0011_m_000001_1, Status : FAILED
[2025-02-27T00:29:34.502+0000] {subprocess.py:106} INFO - Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 2
[2025-02-27T00:29:34.503+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:326)
[2025-02-27T00:29:34.503+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:539)
[2025-02-27T00:29:34.504+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.streaming.PipeMapper.close(PipeMapper.java:130)
[2025-02-27T00:29:34.504+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:61)
[2025-02-27T00:29:34.504+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
[2025-02-27T00:29:34.505+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:466)
[2025-02-27T00:29:34.505+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:350)
[2025-02-27T00:29:34.505+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:178)
[2025-02-27T00:29:34.506+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(Native Method)
[2025-02-27T00:29:34.506+0000] {subprocess.py:106} INFO - 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
[2025-02-27T00:29:34.507+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
[2025-02-27T00:29:34.507+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:172)
[2025-02-27T00:29:34.507+0000] {subprocess.py:106} INFO - 
[2025-02-27T00:29:42.575+0000] {subprocess.py:106} INFO - 2025-02-27 00:29:42,575 INFO mapreduce.Job: Task Id : attempt_1740561960347_0011_m_000000_2, Status : FAILED
[2025-02-27T00:29:42.577+0000] {subprocess.py:106} INFO - Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 2
[2025-02-27T00:29:42.578+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:326)
[2025-02-27T00:29:42.578+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:539)
[2025-02-27T00:29:42.578+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.streaming.PipeMapper.close(PipeMapper.java:130)
[2025-02-27T00:29:42.579+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:61)
[2025-02-27T00:29:42.579+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
[2025-02-27T00:29:42.580+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:466)
[2025-02-27T00:29:42.580+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:350)
[2025-02-27T00:29:42.580+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:178)
[2025-02-27T00:29:42.581+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(Native Method)
[2025-02-27T00:29:42.581+0000] {subprocess.py:106} INFO - 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
[2025-02-27T00:29:42.582+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
[2025-02-27T00:29:42.582+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:172)
[2025-02-27T00:29:42.582+0000] {subprocess.py:106} INFO - 
[2025-02-27T00:29:43.585+0000] {subprocess.py:106} INFO - 2025-02-27 00:29:43,585 INFO mapreduce.Job: Task Id : attempt_1740561960347_0011_m_000001_2, Status : FAILED
[2025-02-27T00:29:43.587+0000] {subprocess.py:106} INFO - Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 2
[2025-02-27T00:29:43.588+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:326)
[2025-02-27T00:29:43.588+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:539)
[2025-02-27T00:29:43.589+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.streaming.PipeMapper.close(PipeMapper.java:130)
[2025-02-27T00:29:43.589+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:61)
[2025-02-27T00:29:43.589+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
[2025-02-27T00:29:43.589+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:466)
[2025-02-27T00:29:43.589+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:350)
[2025-02-27T00:29:43.590+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:178)
[2025-02-27T00:29:43.590+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(Native Method)
[2025-02-27T00:29:43.590+0000] {subprocess.py:106} INFO - 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
[2025-02-27T00:29:43.590+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
[2025-02-27T00:29:43.591+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:172)
[2025-02-27T00:29:43.591+0000] {subprocess.py:106} INFO - 
[2025-02-27T00:29:50.671+0000] {subprocess.py:106} INFO - 2025-02-27 00:29:50,671 INFO mapreduce.Job:  map 100% reduce 100%
[2025-02-27T00:29:50.685+0000] {subprocess.py:106} INFO - 2025-02-27 00:29:50,685 INFO mapreduce.Job: Job job_1740561960347_0011 failed with state FAILED due to: Task failed task_1740561960347_0011_m_000000
[2025-02-27T00:29:50.686+0000] {subprocess.py:106} INFO - Job failed as tasks failed. failedMaps:1 failedReduces:0 killedMaps:0 killedReduces: 0
[2025-02-27T00:29:50.686+0000] {subprocess.py:106} INFO - 
[2025-02-27T00:29:50.845+0000] {subprocess.py:106} INFO - 2025-02-27 00:29:50,845 INFO mapreduce.Job: Counters: 14
[2025-02-27T00:29:50.846+0000] {subprocess.py:106} INFO - 	Job Counters
[2025-02-27T00:29:50.847+0000] {subprocess.py:106} INFO - 		Failed map tasks=7
[2025-02-27T00:29:50.847+0000] {subprocess.py:106} INFO - 		Killed map tasks=1
[2025-02-27T00:29:50.848+0000] {subprocess.py:106} INFO - 		Killed reduce tasks=1
[2025-02-27T00:29:50.848+0000] {subprocess.py:106} INFO - 		Launched map tasks=8
[2025-02-27T00:29:50.849+0000] {subprocess.py:106} INFO - 		Other local map tasks=6
[2025-02-27T00:29:50.850+0000] {subprocess.py:106} INFO - 		Data-local map tasks=2
[2025-02-27T00:29:50.850+0000] {subprocess.py:106} INFO - 		Total time spent by all maps in occupied slots (ms)=41970
[2025-02-27T00:29:50.850+0000] {subprocess.py:106} INFO - 		Total time spent by all reduces in occupied slots (ms)=0
[2025-02-27T00:29:50.851+0000] {subprocess.py:106} INFO - 		Total time spent by all map tasks (ms)=41970
[2025-02-27T00:29:50.851+0000] {subprocess.py:106} INFO - 		Total vcore-milliseconds taken by all map tasks=41970
[2025-02-27T00:29:50.852+0000] {subprocess.py:106} INFO - 		Total megabyte-milliseconds taken by all map tasks=42977280
[2025-02-27T00:29:50.852+0000] {subprocess.py:106} INFO - 	Map-Reduce Framework
[2025-02-27T00:29:50.853+0000] {subprocess.py:106} INFO - 		CPU time spent (ms)=0
[2025-02-27T00:29:50.853+0000] {subprocess.py:106} INFO - 		Physical memory (bytes) snapshot=0
[2025-02-27T00:29:50.853+0000] {subprocess.py:106} INFO - 		Virtual memory (bytes) snapshot=0
[2025-02-27T00:29:50.854+0000] {subprocess.py:106} INFO - 2025-02-27 00:29:50,845 ERROR streaming.StreamJob: Job not successful!
[2025-02-27T00:29:50.854+0000] {subprocess.py:106} INFO - Streaming Command Failed!
[2025-02-27T00:29:51.253+0000] {subprocess.py:110} INFO - Command exited with return code 1
[2025-02-27T00:29:51.265+0000] {taskinstance.py:3313} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 768, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 734, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 424, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 1.
[2025-02-27T00:29:51.275+0000] {taskinstance.py:1226} INFO - Marking task as UP_FOR_RETRY. dag_id=crypto, task_id=mapreduce, run_id=scheduled__2025-02-26T00:00:00+00:00, execution_date=20250226T000000, start_date=20250227T002906, end_date=20250227T002951
[2025-02-27T00:29:51.325+0000] {taskinstance.py:341} INFO - ::group::Post task execution logs
[2025-02-27T00:29:51.325+0000] {standard_task_runner.py:124} ERROR - Failed to execute job 40 for task mapreduce (Bash command failed. The command returned a non-zero exit code 1.; 3492674)
Traceback (most recent call last):
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/task/task_runner/standard_task_runner.py", line 117, in _start_by_fork
    ret = args.func(args, dag=self.dag)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/cli/commands/task_command.py", line 483, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/cli/commands/task_command.py", line 256, in _run_task_by_selected_method
    return _run_raw_task(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/cli/commands/task_command.py", line 341, in _run_raw_task
    return ti._run_raw_task(
           ^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3006, in _run_raw_task
    return _run_raw_task(
           ^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 274, in _run_raw_task
    TaskInstance._execute_task_with_callbacks(
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3161, in _execute_task_with_callbacks
    result = self._execute_task(context, task_orig)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3185, in _execute_task
    return _execute_task(self, context, task_orig)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 768, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 734, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 424, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 1.
[2025-02-27T00:29:51.346+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 1
[2025-02-27T00:29:51.501+0000] {taskinstance.py:3901} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-02-27T00:29:51.503+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-02-27T00:47:45.578+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-02-27T00:47:45.589+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: crypto.mapreduce scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T00:47:45.593+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: crypto.mapreduce scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T00:47:45.594+0000] {taskinstance.py:2867} INFO - Starting attempt 1 of 2
[2025-02-27T00:47:45.602+0000] {taskinstance.py:2890} INFO - Executing <Task(BashOperator): mapreduce> on 2025-02-26 00:00:00+00:00
[2025-02-27T00:47:45.606+0000] {standard_task_runner.py:72} INFO - Started process 3574619 to run task
[2025-02-27T00:47:45.608+0000] {standard_task_runner.py:104} INFO - Running: ['airflow', 'tasks', 'run', 'crypto', 'mapreduce', 'scheduled__2025-02-26T00:00:00+00:00', '--job-id', '48', '--raw', '--subdir', 'DAGS_FOLDER/crypto_dag.py', '--cfg-path', '/tmp/tmpupkxt8rh']
[2025-02-27T00:47:45.609+0000] {standard_task_runner.py:105} INFO - Job 48: Subtask mapreduce
[2025-02-27T00:47:45.633+0000] {task_command.py:467} INFO - Running <TaskInstance: crypto.mapreduce scheduled__2025-02-26T00:00:00+00:00 [running]> on host ali-ThinkBook-14-G2-ITL
[2025-02-27T00:47:45.749+0000] {taskinstance.py:3134} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='ali rahiqi' AIRFLOW_CTX_DAG_ID='crypto' AIRFLOW_CTX_TASK_ID='mapreduce' AIRFLOW_CTX_EXECUTION_DATE='2025-02-26T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-02-26T00:00:00+00:00'
[2025-02-27T00:47:45.749+0000] {taskinstance.py:732} INFO - ::endgroup::
[2025-02-27T00:47:45.758+0000] {subprocess.py:78} INFO - Tmp dir root location: /tmp
[2025-02-27T00:47:45.758+0000] {subprocess.py:88} INFO - Running command: ['/usr/bin/bash', '-c', '\n        hadoop jar /usr/local/hadoop/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar         -input /user/etudiant/crypto/raw/YYYY=2025/MM=02/DD=26/coingecko_raw.json         -output /user/etudiant/crypto/processed/YYYY=2025/MM=02/DD=26         -mapper /home/ali/Desktop/crypto/scripts/mapper.py         -reducer /home/ali/Desktop/crypto/scripts/reducer.py         -file /home/ali/Desktop/crypto/scripts/mapper.py         -file /home/ali/Desktop/crypto/scripts/reducer.py']
[2025-02-27T00:47:45.765+0000] {subprocess.py:99} INFO - Output:
[2025-02-27T00:47:46.163+0000] {subprocess.py:106} INFO - 2025-02-27 00:47:46,163 WARN streaming.StreamJob: -file option is deprecated, please use generic option -files instead.
[2025-02-27T00:47:46.740+0000] {subprocess.py:106} INFO - packageJobJar: [/home/ali/Desktop/crypto/scripts/mapper.py, /home/ali/Desktop/crypto/scripts/reducer.py, /tmp/hadoop-unjar9537774432472236099/] [] /tmp/streamjob2121442037370834470.jar tmpDir=null
[2025-02-27T00:47:46.816+0000] {subprocess.py:106} INFO - 2025-02-27 00:47:46,815 INFO client.DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at /0.0.0.0:8032
[2025-02-27T00:47:46.930+0000] {subprocess.py:106} INFO - 2025-02-27 00:47:46,929 INFO client.DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at /0.0.0.0:8032
[2025-02-27T00:47:46.987+0000] {subprocess.py:106} INFO - 2025-02-27 00:47:46,986 ERROR streaming.StreamJob: Error Launching job : Output directory hdfs://localhost:9000/user/etudiant/crypto/processed/YYYY=2025/MM=02/DD=26 already exists
[2025-02-27T00:47:46.987+0000] {subprocess.py:106} INFO - Streaming Command Failed!
[2025-02-27T00:47:47.335+0000] {subprocess.py:110} INFO - Command exited with return code 5
[2025-02-27T00:47:47.340+0000] {taskinstance.py:3313} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 768, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 734, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 424, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 5.
[2025-02-27T00:47:47.344+0000] {taskinstance.py:1226} INFO - Marking task as UP_FOR_RETRY. dag_id=crypto, task_id=mapreduce, run_id=scheduled__2025-02-26T00:00:00+00:00, execution_date=20250226T000000, start_date=20250227T004745, end_date=20250227T004747
[2025-02-27T00:47:47.369+0000] {taskinstance.py:341} INFO - ::group::Post task execution logs
[2025-02-27T00:47:47.369+0000] {standard_task_runner.py:124} ERROR - Failed to execute job 48 for task mapreduce (Bash command failed. The command returned a non-zero exit code 5.; 3574619)
Traceback (most recent call last):
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/task/task_runner/standard_task_runner.py", line 117, in _start_by_fork
    ret = args.func(args, dag=self.dag)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/cli/commands/task_command.py", line 483, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/cli/commands/task_command.py", line 256, in _run_task_by_selected_method
    return _run_raw_task(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/cli/commands/task_command.py", line 341, in _run_raw_task
    return ti._run_raw_task(
           ^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3006, in _run_raw_task
    return _run_raw_task(
           ^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 274, in _run_raw_task
    TaskInstance._execute_task_with_callbacks(
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3161, in _execute_task_with_callbacks
    result = self._execute_task(context, task_orig)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3185, in _execute_task
    return _execute_task(self, context, task_orig)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 768, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 734, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 424, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 5.
[2025-02-27T00:47:47.386+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 1
[2025-02-27T00:47:47.472+0000] {taskinstance.py:3901} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-02-27T00:47:47.473+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-02-27T01:02:02.991+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-02-27T01:02:03.000+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: crypto.mapreduce scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T01:02:03.005+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: crypto.mapreduce scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T01:02:03.005+0000] {taskinstance.py:2867} INFO - Starting attempt 1 of 2
[2025-02-27T01:02:03.014+0000] {taskinstance.py:2890} INFO - Executing <Task(BashOperator): mapreduce> on 2025-02-26 00:00:00+00:00
[2025-02-27T01:02:03.017+0000] {standard_task_runner.py:72} INFO - Started process 3641295 to run task
[2025-02-27T01:02:03.019+0000] {standard_task_runner.py:104} INFO - Running: ['airflow', 'tasks', 'run', 'crypto', 'mapreduce', 'scheduled__2025-02-26T00:00:00+00:00', '--job-id', '52', '--raw', '--subdir', 'DAGS_FOLDER/crypto_dag.py', '--cfg-path', '/tmp/tmpwz7k6d8x']
[2025-02-27T01:02:03.020+0000] {standard_task_runner.py:105} INFO - Job 52: Subtask mapreduce
[2025-02-27T01:02:03.042+0000] {task_command.py:467} INFO - Running <TaskInstance: crypto.mapreduce scheduled__2025-02-26T00:00:00+00:00 [running]> on host ali-ThinkBook-14-G2-ITL
[2025-02-27T01:02:03.149+0000] {taskinstance.py:3134} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='ali rahiqi' AIRFLOW_CTX_DAG_ID='crypto' AIRFLOW_CTX_TASK_ID='mapreduce' AIRFLOW_CTX_EXECUTION_DATE='2025-02-26T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-02-26T00:00:00+00:00'
[2025-02-27T01:02:03.149+0000] {taskinstance.py:732} INFO - ::endgroup::
[2025-02-27T01:02:03.156+0000] {subprocess.py:78} INFO - Tmp dir root location: /tmp
[2025-02-27T01:02:03.156+0000] {subprocess.py:88} INFO - Running command: ['/usr/bin/bash', '-c', '\n        hadoop jar /usr/local/hadoop/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar         -input /user/etudiant/crypto/raw/YYYY=2025/MM=02/DD=26/coingecko_raw.json         -output /user/etudiant/crypto/processed/YYYY=2025/MM=02/DD=26         -mapper /home/ali/Desktop/crypto/scripts/mapper.py         -reducer /home/ali/Desktop/crypto/scripts/reducer.py         -file /home/ali/Desktop/crypto/scripts/mapper.py         -file /home/ali/Desktop/crypto/scripts/reducer.py']
[2025-02-27T01:02:03.161+0000] {subprocess.py:99} INFO - Output:
[2025-02-27T01:02:03.533+0000] {subprocess.py:106} INFO - 2025-02-27 01:02:03,532 WARN streaming.StreamJob: -file option is deprecated, please use generic option -files instead.
[2025-02-27T01:02:04.006+0000] {subprocess.py:106} INFO - packageJobJar: [/home/ali/Desktop/crypto/scripts/mapper.py, /home/ali/Desktop/crypto/scripts/reducer.py, /tmp/hadoop-unjar18439647650935244050/] [] /tmp/streamjob3179255439288692093.jar tmpDir=null
[2025-02-27T01:02:04.076+0000] {subprocess.py:106} INFO - 2025-02-27 01:02:04,076 INFO client.DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at /0.0.0.0:8032
[2025-02-27T01:02:04.170+0000] {subprocess.py:106} INFO - 2025-02-27 01:02:04,169 INFO client.DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at /0.0.0.0:8032
[2025-02-27T01:02:04.303+0000] {subprocess.py:106} INFO - 2025-02-27 01:02:04,303 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/ali/.staging/job_1740561960347_0013
[2025-02-27T01:02:04.492+0000] {subprocess.py:106} INFO - 2025-02-27 01:02:04,492 INFO mapreduce.JobSubmitter: Cleaning up the staging area /tmp/hadoop-yarn/staging/ali/.staging/job_1740561960347_0013
[2025-02-27T01:02:04.496+0000] {subprocess.py:106} INFO - 2025-02-27 01:02:04,496 ERROR streaming.StreamJob: Error Launching job : Input path does not exist: hdfs://localhost:9000/user/etudiant/crypto/raw/YYYY=2025/MM=02/DD=26/coingecko_raw.json
[2025-02-27T01:02:04.496+0000] {subprocess.py:106} INFO - Streaming Command Failed!
[2025-02-27T01:02:04.836+0000] {subprocess.py:110} INFO - Command exited with return code 5
[2025-02-27T01:02:04.841+0000] {taskinstance.py:3313} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 768, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 734, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 424, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 5.
[2025-02-27T01:02:04.845+0000] {taskinstance.py:1226} INFO - Marking task as UP_FOR_RETRY. dag_id=crypto, task_id=mapreduce, run_id=scheduled__2025-02-26T00:00:00+00:00, execution_date=20250226T000000, start_date=20250227T010203, end_date=20250227T010204
[2025-02-27T01:02:04.885+0000] {taskinstance.py:341} INFO - ::group::Post task execution logs
[2025-02-27T01:02:04.886+0000] {standard_task_runner.py:124} ERROR - Failed to execute job 52 for task mapreduce (Bash command failed. The command returned a non-zero exit code 5.; 3641295)
Traceback (most recent call last):
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/task/task_runner/standard_task_runner.py", line 117, in _start_by_fork
    ret = args.func(args, dag=self.dag)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/cli/commands/task_command.py", line 483, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/cli/commands/task_command.py", line 256, in _run_task_by_selected_method
    return _run_raw_task(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/cli/commands/task_command.py", line 341, in _run_raw_task
    return ti._run_raw_task(
           ^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3006, in _run_raw_task
    return _run_raw_task(
           ^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 274, in _run_raw_task
    TaskInstance._execute_task_with_callbacks(
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3161, in _execute_task_with_callbacks
    result = self._execute_task(context, task_orig)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3185, in _execute_task
    return _execute_task(self, context, task_orig)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 768, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 734, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 424, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 5.
[2025-02-27T01:02:04.916+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 1
[2025-02-27T01:02:05.029+0000] {taskinstance.py:3901} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-02-27T01:02:05.030+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-02-27T01:03:26.817+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-02-27T01:03:26.829+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: crypto.mapreduce scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T01:03:26.834+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: crypto.mapreduce scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T01:03:26.834+0000] {taskinstance.py:2867} INFO - Starting attempt 1 of 2
[2025-02-27T01:03:26.843+0000] {taskinstance.py:2890} INFO - Executing <Task(BashOperator): mapreduce> on 2025-02-26 00:00:00+00:00
[2025-02-27T01:03:26.846+0000] {standard_task_runner.py:72} INFO - Started process 3649453 to run task
[2025-02-27T01:03:26.848+0000] {standard_task_runner.py:104} INFO - Running: ['airflow', 'tasks', 'run', 'crypto', 'mapreduce', 'scheduled__2025-02-26T00:00:00+00:00', '--job-id', '56', '--raw', '--subdir', 'DAGS_FOLDER/crypto_dag.py', '--cfg-path', '/tmp/tmp1ramucph']
[2025-02-27T01:03:26.850+0000] {standard_task_runner.py:105} INFO - Job 56: Subtask mapreduce
[2025-02-27T01:03:26.873+0000] {task_command.py:467} INFO - Running <TaskInstance: crypto.mapreduce scheduled__2025-02-26T00:00:00+00:00 [running]> on host ali-ThinkBook-14-G2-ITL
[2025-02-27T01:03:26.991+0000] {taskinstance.py:3134} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='ali rahiqi' AIRFLOW_CTX_DAG_ID='crypto' AIRFLOW_CTX_TASK_ID='mapreduce' AIRFLOW_CTX_EXECUTION_DATE='2025-02-26T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-02-26T00:00:00+00:00'
[2025-02-27T01:03:26.991+0000] {taskinstance.py:732} INFO - ::endgroup::
[2025-02-27T01:03:26.998+0000] {subprocess.py:78} INFO - Tmp dir root location: /tmp
[2025-02-27T01:03:26.998+0000] {subprocess.py:88} INFO - Running command: ['/usr/bin/bash', '-c', '\n        hadoop jar /usr/local/hadoop/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar         -input /user/etudiant/crypto/raw/YYYY=2025/MM=02/DD=26/coingecko_raw.json         -output /user/etudiant/crypto/processed/YYYY=2025/MM=02/DD=26         -mapper /home/ali/Desktop/crypto/scripts/mapper.py         -reducer /home/ali/Desktop/crypto/scripts/reducer.py         -file /home/ali/Desktop/crypto/scripts/mapper.py         -file /home/ali/Desktop/crypto/scripts/reducer.py']
[2025-02-27T01:03:27.007+0000] {subprocess.py:99} INFO - Output:
[2025-02-27T01:03:27.443+0000] {subprocess.py:106} INFO - 2025-02-27 01:03:27,443 WARN streaming.StreamJob: -file option is deprecated, please use generic option -files instead.
[2025-02-27T01:03:27.919+0000] {subprocess.py:106} INFO - packageJobJar: [/home/ali/Desktop/crypto/scripts/mapper.py, /home/ali/Desktop/crypto/scripts/reducer.py, /tmp/hadoop-unjar1100578281554155332/] [] /tmp/streamjob1761547668217558214.jar tmpDir=null
[2025-02-27T01:03:27.996+0000] {subprocess.py:106} INFO - 2025-02-27 01:03:27,996 INFO client.DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at /0.0.0.0:8032
[2025-02-27T01:03:28.106+0000] {subprocess.py:106} INFO - 2025-02-27 01:03:28,106 INFO client.DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at /0.0.0.0:8032
[2025-02-27T01:03:28.247+0000] {subprocess.py:106} INFO - 2025-02-27 01:03:28,247 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/ali/.staging/job_1740561960347_0015
[2025-02-27T01:03:28.447+0000] {subprocess.py:106} INFO - 2025-02-27 01:03:28,447 INFO mapreduce.JobSubmitter: Cleaning up the staging area /tmp/hadoop-yarn/staging/ali/.staging/job_1740561960347_0015
[2025-02-27T01:03:28.451+0000] {subprocess.py:106} INFO - 2025-02-27 01:03:28,451 ERROR streaming.StreamJob: Error Launching job : Input path does not exist: hdfs://localhost:9000/user/etudiant/crypto/raw/YYYY=2025/MM=02/DD=26/coingecko_raw.json
[2025-02-27T01:03:28.451+0000] {subprocess.py:106} INFO - Streaming Command Failed!
[2025-02-27T01:03:28.802+0000] {subprocess.py:110} INFO - Command exited with return code 5
[2025-02-27T01:03:28.807+0000] {taskinstance.py:3313} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 768, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 734, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 424, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 5.
[2025-02-27T01:03:28.810+0000] {taskinstance.py:1226} INFO - Marking task as UP_FOR_RETRY. dag_id=crypto, task_id=mapreduce, run_id=scheduled__2025-02-26T00:00:00+00:00, execution_date=20250226T000000, start_date=20250227T010326, end_date=20250227T010328
[2025-02-27T01:03:28.833+0000] {taskinstance.py:341} INFO - ::group::Post task execution logs
[2025-02-27T01:03:28.833+0000] {standard_task_runner.py:124} ERROR - Failed to execute job 56 for task mapreduce (Bash command failed. The command returned a non-zero exit code 5.; 3649453)
Traceback (most recent call last):
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/task/task_runner/standard_task_runner.py", line 117, in _start_by_fork
    ret = args.func(args, dag=self.dag)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/cli/commands/task_command.py", line 483, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/cli/commands/task_command.py", line 256, in _run_task_by_selected_method
    return _run_raw_task(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/cli/commands/task_command.py", line 341, in _run_raw_task
    return ti._run_raw_task(
           ^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3006, in _run_raw_task
    return _run_raw_task(
           ^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 274, in _run_raw_task
    TaskInstance._execute_task_with_callbacks(
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3161, in _execute_task_with_callbacks
    result = self._execute_task(context, task_orig)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3185, in _execute_task
    return _execute_task(self, context, task_orig)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 768, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 734, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 424, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 5.
[2025-02-27T01:03:28.866+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 1
[2025-02-27T01:03:28.955+0000] {taskinstance.py:3901} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-02-27T01:03:28.956+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-02-27T01:25:23.121+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-02-27T01:25:23.155+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: crypto.mapreduce scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T01:25:23.167+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: crypto.mapreduce scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T01:25:23.168+0000] {taskinstance.py:2867} INFO - Starting attempt 1 of 2
[2025-02-27T01:25:23.179+0000] {taskinstance.py:2890} INFO - Executing <Task(BashOperator): mapreduce> on 2025-02-26 00:00:00+00:00
[2025-02-27T01:25:23.184+0000] {standard_task_runner.py:72} INFO - Started process 3749477 to run task
[2025-02-27T01:25:23.186+0000] {standard_task_runner.py:104} INFO - Running: ['airflow', 'tasks', 'run', 'crypto', 'mapreduce', 'scheduled__2025-02-26T00:00:00+00:00', '--job-id', '60', '--raw', '--subdir', 'DAGS_FOLDER/crypto_dag.py', '--cfg-path', '/tmp/tmptfk4eq1s']
[2025-02-27T01:25:23.187+0000] {standard_task_runner.py:105} INFO - Job 60: Subtask mapreduce
[2025-02-27T01:25:23.219+0000] {task_command.py:467} INFO - Running <TaskInstance: crypto.mapreduce scheduled__2025-02-26T00:00:00+00:00 [running]> on host ali-ThinkBook-14-G2-ITL
[2025-02-27T01:25:23.386+0000] {taskinstance.py:3134} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='ali rahiqi' AIRFLOW_CTX_DAG_ID='crypto' AIRFLOW_CTX_TASK_ID='mapreduce' AIRFLOW_CTX_EXECUTION_DATE='2025-02-26T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-02-26T00:00:00+00:00'
[2025-02-27T01:25:23.387+0000] {taskinstance.py:732} INFO - ::endgroup::
[2025-02-27T01:25:23.397+0000] {subprocess.py:78} INFO - Tmp dir root location: /tmp
[2025-02-27T01:25:23.397+0000] {subprocess.py:88} INFO - Running command: ['/usr/bin/bash', '-c', '\n        hadoop jar /usr/local/hadoop/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar         -input /user/etudiant/crypto/raw/YYYY=2025/MM=02/DD=26/coingecko_raw.json         -output /user/etudiant/crypto/processed/YYYY=2025/MM=02/DD=26         -mapper /home/ali/Desktop/crypto/scripts/mapper.py         -reducer /home/ali/Desktop/crypto/scripts/reducer.py         -file /home/ali/Desktop/crypto/scripts/mapper.py         -file /home/ali/Desktop/crypto/scripts/reducer.py']
[2025-02-27T01:25:23.406+0000] {subprocess.py:99} INFO - Output:
[2025-02-27T01:25:24.000+0000] {subprocess.py:106} INFO - 2025-02-27 01:25:24,000 WARN streaming.StreamJob: -file option is deprecated, please use generic option -files instead.
[2025-02-27T01:25:24.629+0000] {subprocess.py:106} INFO - packageJobJar: [/home/ali/Desktop/crypto/scripts/mapper.py, /home/ali/Desktop/crypto/scripts/reducer.py, /tmp/hadoop-unjar2145292045086057727/] [] /tmp/streamjob6731981166245638518.jar tmpDir=null
[2025-02-27T01:25:24.762+0000] {subprocess.py:106} INFO - 2025-02-27 01:25:24,762 INFO client.DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at /0.0.0.0:8032
[2025-02-27T01:25:24.899+0000] {subprocess.py:106} INFO - 2025-02-27 01:25:24,899 INFO client.DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at /0.0.0.0:8032
[2025-02-27T01:25:25.076+0000] {subprocess.py:106} INFO - 2025-02-27 01:25:25,076 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/ali/.staging/job_1740561960347_0017
[2025-02-27T01:25:25.398+0000] {subprocess.py:106} INFO - 2025-02-27 01:25:25,397 INFO mapreduce.JobSubmitter: Cleaning up the staging area /tmp/hadoop-yarn/staging/ali/.staging/job_1740561960347_0017
[2025-02-27T01:25:25.405+0000] {subprocess.py:106} INFO - 2025-02-27 01:25:25,405 ERROR streaming.StreamJob: Error Launching job : Input path does not exist: hdfs://localhost:9000/user/etudiant/crypto/raw/YYYY=2025/MM=02/DD=26/coingecko_raw.json
[2025-02-27T01:25:25.406+0000] {subprocess.py:106} INFO - Streaming Command Failed!
[2025-02-27T01:25:25.764+0000] {subprocess.py:110} INFO - Command exited with return code 5
[2025-02-27T01:25:25.770+0000] {taskinstance.py:3313} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 768, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 734, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 424, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 5.
[2025-02-27T01:25:25.775+0000] {taskinstance.py:1226} INFO - Marking task as UP_FOR_RETRY. dag_id=crypto, task_id=mapreduce, run_id=scheduled__2025-02-26T00:00:00+00:00, execution_date=20250226T000000, start_date=20250227T012523, end_date=20250227T012525
[2025-02-27T01:25:25.803+0000] {taskinstance.py:341} INFO - ::group::Post task execution logs
[2025-02-27T01:25:25.803+0000] {standard_task_runner.py:124} ERROR - Failed to execute job 60 for task mapreduce (Bash command failed. The command returned a non-zero exit code 5.; 3749477)
Traceback (most recent call last):
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/task/task_runner/standard_task_runner.py", line 117, in _start_by_fork
    ret = args.func(args, dag=self.dag)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/cli/commands/task_command.py", line 483, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/cli/commands/task_command.py", line 256, in _run_task_by_selected_method
    return _run_raw_task(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/cli/commands/task_command.py", line 341, in _run_raw_task
    return ti._run_raw_task(
           ^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3006, in _run_raw_task
    return _run_raw_task(
           ^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 274, in _run_raw_task
    TaskInstance._execute_task_with_callbacks(
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3161, in _execute_task_with_callbacks
    result = self._execute_task(context, task_orig)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3185, in _execute_task
    return _execute_task(self, context, task_orig)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 768, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 734, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 424, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 5.
[2025-02-27T01:25:25.845+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 1
[2025-02-27T01:25:25.943+0000] {taskinstance.py:3901} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-02-27T01:25:25.944+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-02-27T01:31:48.657+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-02-27T01:31:48.671+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: crypto.mapreduce scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T01:31:48.678+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: crypto.mapreduce scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T01:31:48.678+0000] {taskinstance.py:2867} INFO - Starting attempt 1 of 2
[2025-02-27T01:31:48.689+0000] {taskinstance.py:2890} INFO - Executing <Task(BashOperator): mapreduce> on 2025-02-26 00:00:00+00:00
[2025-02-27T01:31:48.693+0000] {standard_task_runner.py:72} INFO - Started process 3777998 to run task
[2025-02-27T01:31:48.695+0000] {standard_task_runner.py:104} INFO - Running: ['airflow', 'tasks', 'run', 'crypto', 'mapreduce', 'scheduled__2025-02-26T00:00:00+00:00', '--job-id', '64', '--raw', '--subdir', 'DAGS_FOLDER/crypto_dag.py', '--cfg-path', '/tmp/tmploaqgkfw']
[2025-02-27T01:31:48.697+0000] {standard_task_runner.py:105} INFO - Job 64: Subtask mapreduce
[2025-02-27T01:31:48.726+0000] {task_command.py:467} INFO - Running <TaskInstance: crypto.mapreduce scheduled__2025-02-26T00:00:00+00:00 [running]> on host ali-ThinkBook-14-G2-ITL
[2025-02-27T01:31:48.885+0000] {taskinstance.py:3134} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='ali rahiqi' AIRFLOW_CTX_DAG_ID='crypto' AIRFLOW_CTX_TASK_ID='mapreduce' AIRFLOW_CTX_EXECUTION_DATE='2025-02-26T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-02-26T00:00:00+00:00'
[2025-02-27T01:31:48.886+0000] {taskinstance.py:732} INFO - ::endgroup::
[2025-02-27T01:31:48.895+0000] {subprocess.py:78} INFO - Tmp dir root location: /tmp
[2025-02-27T01:31:48.896+0000] {subprocess.py:88} INFO - Running command: ['/usr/bin/bash', '-c', '\n        hadoop jar /usr/local/hadoop/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar         -input /user/etudiant/crypto/raw/YYYY=2025/MM=02/DD=26/coingecko_raw.json         -output /user/etudiant/crypto/processed/YYYY=2025/MM=02/DD=26         -mapper /home/ali/Desktop/crypto/scripts/mapper.py         -reducer /home/ali/Desktop/crypto/scripts/reducer.py         -file /home/ali/Desktop/crypto/scripts/mapper.py         -file /home/ali/Desktop/crypto/scripts/reducer.py']
[2025-02-27T01:31:48.904+0000] {subprocess.py:99} INFO - Output:
[2025-02-27T01:31:49.465+0000] {subprocess.py:106} INFO - 2025-02-27 01:31:49,464 WARN streaming.StreamJob: -file option is deprecated, please use generic option -files instead.
[2025-02-27T01:31:50.100+0000] {subprocess.py:106} INFO - packageJobJar: [/home/ali/Desktop/crypto/scripts/mapper.py, /home/ali/Desktop/crypto/scripts/reducer.py, /tmp/hadoop-unjar2429303309950226856/] [] /tmp/streamjob13380927474413009060.jar tmpDir=null
[2025-02-27T01:31:50.218+0000] {subprocess.py:106} INFO - 2025-02-27 01:31:50,218 INFO client.DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at /0.0.0.0:8032
[2025-02-27T01:31:50.339+0000] {subprocess.py:106} INFO - 2025-02-27 01:31:50,339 INFO client.DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at /0.0.0.0:8032
[2025-02-27T01:31:50.509+0000] {subprocess.py:106} INFO - 2025-02-27 01:31:50,509 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/ali/.staging/job_1740561960347_0020
[2025-02-27T01:31:51.224+0000] {subprocess.py:106} INFO - 2025-02-27 01:31:51,224 INFO mapreduce.JobSubmitter: Cleaning up the staging area /tmp/hadoop-yarn/staging/ali/.staging/job_1740561960347_0020
[2025-02-27T01:31:51.232+0000] {subprocess.py:106} INFO - 2025-02-27 01:31:51,231 ERROR streaming.StreamJob: Error Launching job : Input path does not exist: hdfs://localhost:9000/user/etudiant/crypto/raw/YYYY=2025/MM=02/DD=26/coingecko_raw.json
[2025-02-27T01:31:51.232+0000] {subprocess.py:106} INFO - Streaming Command Failed!
[2025-02-27T01:31:51.593+0000] {subprocess.py:110} INFO - Command exited with return code 5
[2025-02-27T01:31:51.606+0000] {taskinstance.py:3313} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 768, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 734, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 424, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 5.
[2025-02-27T01:31:51.617+0000] {taskinstance.py:1226} INFO - Marking task as UP_FOR_RETRY. dag_id=crypto, task_id=mapreduce, run_id=scheduled__2025-02-26T00:00:00+00:00, execution_date=20250226T000000, start_date=20250227T013148, end_date=20250227T013151
[2025-02-27T01:31:51.661+0000] {taskinstance.py:341} INFO - ::group::Post task execution logs
[2025-02-27T01:31:51.662+0000] {standard_task_runner.py:124} ERROR - Failed to execute job 64 for task mapreduce (Bash command failed. The command returned a non-zero exit code 5.; 3777998)
Traceback (most recent call last):
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/task/task_runner/standard_task_runner.py", line 117, in _start_by_fork
    ret = args.func(args, dag=self.dag)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/cli/commands/task_command.py", line 483, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/cli/commands/task_command.py", line 256, in _run_task_by_selected_method
    return _run_raw_task(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/cli/commands/task_command.py", line 341, in _run_raw_task
    return ti._run_raw_task(
           ^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3006, in _run_raw_task
    return _run_raw_task(
           ^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 274, in _run_raw_task
    TaskInstance._execute_task_with_callbacks(
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3161, in _execute_task_with_callbacks
    result = self._execute_task(context, task_orig)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3185, in _execute_task
    return _execute_task(self, context, task_orig)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 768, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 734, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 424, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 5.
[2025-02-27T01:31:51.716+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 1
[2025-02-27T01:31:51.839+0000] {taskinstance.py:3901} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-02-27T01:31:51.840+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-02-27T09:33:27.360+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-02-27T09:33:27.371+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: crypto.mapreduce scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T09:33:27.377+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: crypto.mapreduce scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T09:33:27.377+0000] {taskinstance.py:2867} INFO - Starting attempt 1 of 2
[2025-02-27T09:33:27.386+0000] {taskinstance.py:2890} INFO - Executing <Task(BashOperator): mapreduce> on 2025-02-26 00:00:00+00:00
[2025-02-27T09:33:27.390+0000] {standard_task_runner.py:72} INFO - Started process 91611 to run task
[2025-02-27T09:33:27.391+0000] {standard_task_runner.py:104} INFO - Running: ['airflow', 'tasks', 'run', 'crypto', 'mapreduce', 'scheduled__2025-02-26T00:00:00+00:00', '--job-id', '68', '--raw', '--subdir', 'DAGS_FOLDER/crypto_dag.py', '--cfg-path', '/tmp/tmpd5hicxbi']
[2025-02-27T09:33:27.392+0000] {standard_task_runner.py:105} INFO - Job 68: Subtask mapreduce
[2025-02-27T09:33:27.414+0000] {task_command.py:467} INFO - Running <TaskInstance: crypto.mapreduce scheduled__2025-02-26T00:00:00+00:00 [running]> on host ali-ThinkBook-14-G2-ITL
[2025-02-27T09:33:27.537+0000] {taskinstance.py:3134} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='ali rahiqi' AIRFLOW_CTX_DAG_ID='crypto' AIRFLOW_CTX_TASK_ID='mapreduce' AIRFLOW_CTX_EXECUTION_DATE='2025-02-26T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-02-26T00:00:00+00:00'
[2025-02-27T09:33:27.538+0000] {taskinstance.py:732} INFO - ::endgroup::
[2025-02-27T09:33:27.545+0000] {subprocess.py:78} INFO - Tmp dir root location: /tmp
[2025-02-27T09:33:27.546+0000] {subprocess.py:88} INFO - Running command: ['/usr/bin/bash', '-c', '\n        hadoop jar /usr/local/hadoop/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar         -input /user/etudiant/crypto/raw/YYYY=2025/MM=02/DD=26/coingecko_raw.json         -output /user/etudiant/crypto/processed/YYYY=2025/MM=02/DD=26         -mapper /home/ali/Desktop/crypto/scripts/mapper.py         -reducer /home/ali/Desktop/crypto/scripts/reducer.py         -file /home/ali/Desktop/crypto/scripts/mapper.py         -file /home/ali/Desktop/crypto/scripts/reducer.py']
[2025-02-27T09:33:27.553+0000] {subprocess.py:99} INFO - Output:
[2025-02-27T09:33:28.276+0000] {subprocess.py:106} INFO - 2025-02-27 09:33:28,272 WARN streaming.StreamJob: -file option is deprecated, please use generic option -files instead.
[2025-02-27T09:33:29.099+0000] {subprocess.py:106} INFO - packageJobJar: [/home/ali/Desktop/crypto/scripts/mapper.py, /home/ali/Desktop/crypto/scripts/reducer.py, /tmp/hadoop-unjar3420144384699044318/] [] /tmp/streamjob16079719679684857495.jar tmpDir=null
[2025-02-27T09:33:29.210+0000] {subprocess.py:106} INFO - 2025-02-27 09:33:29,210 INFO client.DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at /0.0.0.0:8032
[2025-02-27T09:33:29.363+0000] {subprocess.py:106} INFO - 2025-02-27 09:33:29,362 INFO client.DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at /0.0.0.0:8032
[2025-02-27T09:33:29.543+0000] {subprocess.py:106} INFO - 2025-02-27 09:33:29,543 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/ali/.staging/job_1740648251068_0001
[2025-02-27T09:33:29.860+0000] {subprocess.py:106} INFO - 2025-02-27 09:33:29,860 INFO mapreduce.JobSubmitter: Cleaning up the staging area /tmp/hadoop-yarn/staging/ali/.staging/job_1740648251068_0001
[2025-02-27T09:33:29.865+0000] {subprocess.py:106} INFO - 2025-02-27 09:33:29,865 ERROR streaming.StreamJob: Error Launching job : Input path does not exist: hdfs://localhost:9000/user/etudiant/crypto/raw/YYYY=2025/MM=02/DD=26/coingecko_raw.json
[2025-02-27T09:33:29.865+0000] {subprocess.py:106} INFO - Streaming Command Failed!
[2025-02-27T09:33:30.207+0000] {subprocess.py:110} INFO - Command exited with return code 5
[2025-02-27T09:33:30.212+0000] {taskinstance.py:3313} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 768, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 734, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 424, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 5.
[2025-02-27T09:33:30.223+0000] {taskinstance.py:1226} INFO - Marking task as UP_FOR_RETRY. dag_id=crypto, task_id=mapreduce, run_id=scheduled__2025-02-26T00:00:00+00:00, execution_date=20250226T000000, start_date=20250227T093327, end_date=20250227T093330
[2025-02-27T09:33:30.239+0000] {taskinstance.py:341} INFO - ::group::Post task execution logs
[2025-02-27T09:33:30.239+0000] {standard_task_runner.py:124} ERROR - Failed to execute job 68 for task mapreduce (Bash command failed. The command returned a non-zero exit code 5.; 91611)
Traceback (most recent call last):
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/task/task_runner/standard_task_runner.py", line 117, in _start_by_fork
    ret = args.func(args, dag=self.dag)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/cli/commands/task_command.py", line 483, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/cli/commands/task_command.py", line 256, in _run_task_by_selected_method
    return _run_raw_task(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/cli/commands/task_command.py", line 341, in _run_raw_task
    return ti._run_raw_task(
           ^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3006, in _run_raw_task
    return _run_raw_task(
           ^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 274, in _run_raw_task
    TaskInstance._execute_task_with_callbacks(
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3161, in _execute_task_with_callbacks
    result = self._execute_task(context, task_orig)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3185, in _execute_task
    return _execute_task(self, context, task_orig)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 768, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 734, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 424, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 5.
[2025-02-27T09:33:30.264+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 1
[2025-02-27T09:33:30.337+0000] {taskinstance.py:3901} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-02-27T09:33:30.338+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-02-27T09:41:53.253+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-02-27T09:41:53.274+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: crypto.mapreduce scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T09:41:53.283+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: crypto.mapreduce scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T09:41:53.283+0000] {taskinstance.py:2867} INFO - Starting attempt 1 of 2
[2025-02-27T09:41:53.294+0000] {taskinstance.py:2890} INFO - Executing <Task(BashOperator): mapreduce> on 2025-02-26 00:00:00+00:00
[2025-02-27T09:41:53.298+0000] {standard_task_runner.py:72} INFO - Started process 133305 to run task
[2025-02-27T09:41:53.301+0000] {standard_task_runner.py:104} INFO - Running: ['airflow', 'tasks', 'run', 'crypto', 'mapreduce', 'scheduled__2025-02-26T00:00:00+00:00', '--job-id', '75', '--raw', '--subdir', 'DAGS_FOLDER/crypto_dag.py', '--cfg-path', '/tmp/tmp6gmozi7l']
[2025-02-27T09:41:53.303+0000] {standard_task_runner.py:105} INFO - Job 75: Subtask mapreduce
[2025-02-27T09:41:53.349+0000] {task_command.py:467} INFO - Running <TaskInstance: crypto.mapreduce scheduled__2025-02-26T00:00:00+00:00 [running]> on host ali-ThinkBook-14-G2-ITL
[2025-02-27T09:41:53.501+0000] {taskinstance.py:3134} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='ali rahiqi' AIRFLOW_CTX_DAG_ID='crypto' AIRFLOW_CTX_TASK_ID='mapreduce' AIRFLOW_CTX_EXECUTION_DATE='2025-02-26T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-02-26T00:00:00+00:00'
[2025-02-27T09:41:53.502+0000] {taskinstance.py:732} INFO - ::endgroup::
[2025-02-27T09:41:53.510+0000] {subprocess.py:78} INFO - Tmp dir root location: /tmp
[2025-02-27T09:41:53.510+0000] {subprocess.py:88} INFO - Running command: ['/usr/bin/bash', '-c', '\n        hadoop jar /usr/local/hadoop/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar         -input /user/etudiant/crypto/raw/YYYY=2025/MM=02/DD=26/coingecko_raw.json         -output /user/etudiant/crypto/processed/YYYY=2025/MM=02/DD=26         -mapper /home/ali/Desktop/crypto/scripts/mapper.py         -reducer /home/ali/Desktop/crypto/scripts/reducer.py         -file /home/ali/Desktop/crypto/scripts/mapper.py         -file /home/ali/Desktop/crypto/scripts/reducer.py']
[2025-02-27T09:41:53.517+0000] {subprocess.py:99} INFO - Output:
[2025-02-27T09:41:54.055+0000] {subprocess.py:106} INFO - 2025-02-27 09:41:54,055 WARN streaming.StreamJob: -file option is deprecated, please use generic option -files instead.
[2025-02-27T09:41:54.764+0000] {subprocess.py:106} INFO - packageJobJar: [/home/ali/Desktop/crypto/scripts/mapper.py, /home/ali/Desktop/crypto/scripts/reducer.py, /tmp/hadoop-unjar14836257223596755520/] [] /tmp/streamjob4062036622818520897.jar tmpDir=null
[2025-02-27T09:41:54.885+0000] {subprocess.py:106} INFO - 2025-02-27 09:41:54,885 INFO client.DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at /0.0.0.0:8032
[2025-02-27T09:41:55.009+0000] {subprocess.py:106} INFO - 2025-02-27 09:41:55,008 INFO client.DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at /0.0.0.0:8032
[2025-02-27T09:41:55.223+0000] {subprocess.py:106} INFO - 2025-02-27 09:41:55,223 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/ali/.staging/job_1740648251068_0003
[2025-02-27T09:41:55.494+0000] {subprocess.py:106} INFO - 2025-02-27 09:41:55,494 INFO mapreduce.JobSubmitter: Cleaning up the staging area /tmp/hadoop-yarn/staging/ali/.staging/job_1740648251068_0003
[2025-02-27T09:41:55.498+0000] {subprocess.py:106} INFO - 2025-02-27 09:41:55,498 ERROR streaming.StreamJob: Error Launching job : Input path does not exist: hdfs://localhost:9000/user/etudiant/crypto/raw/YYYY=2025/MM=02/DD=26/coingecko_raw.json
[2025-02-27T09:41:55.498+0000] {subprocess.py:106} INFO - Streaming Command Failed!
[2025-02-27T09:41:55.840+0000] {subprocess.py:110} INFO - Command exited with return code 5
[2025-02-27T09:41:55.845+0000] {taskinstance.py:3313} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 768, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 734, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 424, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 5.
[2025-02-27T09:41:55.849+0000] {taskinstance.py:1226} INFO - Marking task as UP_FOR_RETRY. dag_id=crypto, task_id=mapreduce, run_id=scheduled__2025-02-26T00:00:00+00:00, execution_date=20250226T000000, start_date=20250227T094153, end_date=20250227T094155
[2025-02-27T09:41:55.889+0000] {taskinstance.py:341} INFO - ::group::Post task execution logs
[2025-02-27T09:41:55.890+0000] {standard_task_runner.py:124} ERROR - Failed to execute job 75 for task mapreduce (Bash command failed. The command returned a non-zero exit code 5.; 133305)
Traceback (most recent call last):
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/task/task_runner/standard_task_runner.py", line 117, in _start_by_fork
    ret = args.func(args, dag=self.dag)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/cli/commands/task_command.py", line 483, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/cli/commands/task_command.py", line 256, in _run_task_by_selected_method
    return _run_raw_task(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/cli/commands/task_command.py", line 341, in _run_raw_task
    return ti._run_raw_task(
           ^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3006, in _run_raw_task
    return _run_raw_task(
           ^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 274, in _run_raw_task
    TaskInstance._execute_task_with_callbacks(
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3161, in _execute_task_with_callbacks
    result = self._execute_task(context, task_orig)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3185, in _execute_task
    return _execute_task(self, context, task_orig)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 768, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 734, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 424, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 5.
[2025-02-27T09:41:55.922+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 1
[2025-02-27T09:41:56.006+0000] {taskinstance.py:3901} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-02-27T09:41:56.006+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-02-27T10:05:39.477+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-02-27T10:05:39.487+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: crypto.mapreduce scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T10:05:39.492+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: crypto.mapreduce scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T10:05:39.492+0000] {taskinstance.py:2867} INFO - Starting attempt 1 of 2
[2025-02-27T10:05:39.501+0000] {taskinstance.py:2890} INFO - Executing <Task(BashOperator): mapreduce> on 2025-02-26 00:00:00+00:00
[2025-02-27T10:05:39.504+0000] {standard_task_runner.py:72} INFO - Started process 244393 to run task
[2025-02-27T10:05:39.505+0000] {standard_task_runner.py:104} INFO - Running: ['airflow', 'tasks', 'run', 'crypto', 'mapreduce', 'scheduled__2025-02-26T00:00:00+00:00', '--job-id', '79', '--raw', '--subdir', 'DAGS_FOLDER/crypto_dag.py', '--cfg-path', '/tmp/tmpgj3aid9l']
[2025-02-27T10:05:39.506+0000] {standard_task_runner.py:105} INFO - Job 79: Subtask mapreduce
[2025-02-27T10:05:39.535+0000] {task_command.py:467} INFO - Running <TaskInstance: crypto.mapreduce scheduled__2025-02-26T00:00:00+00:00 [running]> on host ali-ThinkBook-14-G2-ITL
[2025-02-27T10:05:39.669+0000] {taskinstance.py:3134} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='ali rahiqi' AIRFLOW_CTX_DAG_ID='crypto' AIRFLOW_CTX_TASK_ID='mapreduce' AIRFLOW_CTX_EXECUTION_DATE='2025-02-26T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-02-26T00:00:00+00:00'
[2025-02-27T10:05:39.670+0000] {taskinstance.py:732} INFO - ::endgroup::
[2025-02-27T10:05:39.679+0000] {subprocess.py:78} INFO - Tmp dir root location: /tmp
[2025-02-27T10:05:39.680+0000] {subprocess.py:88} INFO - Running command: ['/usr/bin/bash', '-c', '\n        hadoop jar /usr/local/hadoop/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar         -input /user/etudiant/crypto/raw/YYYY=2025/MM=02/DD=26/coingecko_raw.json         -output /user/etudiant/crypto/processed/YYYY=2025/MM=02/DD=26         -mapper scripts/mapper.py         -reducer scripts/reducer.py         -file scripts/mapper.py         -file scripts/reducer.py']
[2025-02-27T10:05:39.688+0000] {subprocess.py:99} INFO - Output:
[2025-02-27T10:05:40.181+0000] {subprocess.py:106} INFO - 2025-02-27 10:05:40,180 WARN streaming.StreamJob: -file option is deprecated, please use generic option -files instead.
[2025-02-27T10:05:40.453+0000] {subprocess.py:106} INFO - File: file:/tmp/airflowtmp1sw95d6s/scripts/mapper.py does not exist.
[2025-02-27T10:05:40.453+0000] {subprocess.py:106} INFO - Try -help for more information
[2025-02-27T10:05:40.453+0000] {subprocess.py:106} INFO - Streaming Command Failed!
[2025-02-27T10:05:40.514+0000] {subprocess.py:110} INFO - Command exited with return code 1
[2025-02-27T10:05:40.521+0000] {taskinstance.py:3313} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 768, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 734, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 424, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 1.
[2025-02-27T10:05:40.528+0000] {taskinstance.py:1226} INFO - Marking task as UP_FOR_RETRY. dag_id=crypto, task_id=mapreduce, run_id=scheduled__2025-02-26T00:00:00+00:00, execution_date=20250226T000000, start_date=20250227T100539, end_date=20250227T100540
[2025-02-27T10:05:40.557+0000] {taskinstance.py:341} INFO - ::group::Post task execution logs
[2025-02-27T10:05:40.558+0000] {standard_task_runner.py:124} ERROR - Failed to execute job 79 for task mapreduce (Bash command failed. The command returned a non-zero exit code 1.; 244393)
Traceback (most recent call last):
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/task/task_runner/standard_task_runner.py", line 117, in _start_by_fork
    ret = args.func(args, dag=self.dag)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/cli/commands/task_command.py", line 483, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/cli/commands/task_command.py", line 256, in _run_task_by_selected_method
    return _run_raw_task(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/cli/commands/task_command.py", line 341, in _run_raw_task
    return ti._run_raw_task(
           ^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3006, in _run_raw_task
    return _run_raw_task(
           ^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 274, in _run_raw_task
    TaskInstance._execute_task_with_callbacks(
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3161, in _execute_task_with_callbacks
    result = self._execute_task(context, task_orig)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3185, in _execute_task
    return _execute_task(self, context, task_orig)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 768, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 734, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 424, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 1.
[2025-02-27T10:05:40.600+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 1
[2025-02-27T10:05:40.687+0000] {taskinstance.py:3901} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-02-27T10:05:40.688+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-02-27T10:18:53.114+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-02-27T10:18:53.124+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: crypto.mapreduce scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T10:18:53.129+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: crypto.mapreduce scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T10:18:53.129+0000] {taskinstance.py:2867} INFO - Starting attempt 1 of 2
[2025-02-27T10:18:53.138+0000] {taskinstance.py:2890} INFO - Executing <Task(BashOperator): mapreduce> on 2025-02-26 00:00:00+00:00
[2025-02-27T10:18:53.142+0000] {standard_task_runner.py:72} INFO - Started process 306760 to run task
[2025-02-27T10:18:53.144+0000] {standard_task_runner.py:104} INFO - Running: ['airflow', 'tasks', 'run', 'crypto', 'mapreduce', 'scheduled__2025-02-26T00:00:00+00:00', '--job-id', '84', '--raw', '--subdir', 'DAGS_FOLDER/crypto_dag.py', '--cfg-path', '/tmp/tmp2856oi0e']
[2025-02-27T10:18:53.145+0000] {standard_task_runner.py:105} INFO - Job 84: Subtask mapreduce
[2025-02-27T10:18:53.168+0000] {task_command.py:467} INFO - Running <TaskInstance: crypto.mapreduce scheduled__2025-02-26T00:00:00+00:00 [running]> on host ali-ThinkBook-14-G2-ITL
[2025-02-27T10:18:53.278+0000] {taskinstance.py:3134} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='ali rahiqi' AIRFLOW_CTX_DAG_ID='crypto' AIRFLOW_CTX_TASK_ID='mapreduce' AIRFLOW_CTX_EXECUTION_DATE='2025-02-26T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-02-26T00:00:00+00:00'
[2025-02-27T10:18:53.279+0000] {taskinstance.py:732} INFO - ::endgroup::
[2025-02-27T10:18:53.285+0000] {subprocess.py:78} INFO - Tmp dir root location: /tmp
[2025-02-27T10:18:53.286+0000] {subprocess.py:88} INFO - Running command: ['/usr/bin/bash', '-c', '\n        hadoop jar /usr/local/hadoop/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar         -input /user/etudiant/crypto/raw/YYYY=2025/MM=02/DD=26/coingecko_raw.json         -output /user/etudiant/crypto/processed/YYYY=2025/MM=02/DD=26         -mapper scripts/mapper.py         -reducer scripts/reducer.py         -file scripts/mapper.py         -file scripts/reducer.py']
[2025-02-27T10:18:53.293+0000] {subprocess.py:99} INFO - Output:
[2025-02-27T10:18:53.855+0000] {subprocess.py:106} INFO - 2025-02-27 10:18:53,854 WARN streaming.StreamJob: -file option is deprecated, please use generic option -files instead.
[2025-02-27T10:18:54.153+0000] {subprocess.py:106} INFO - File: file:/tmp/airflowtmpm1_o82x7/scripts/mapper.py does not exist.
[2025-02-27T10:18:54.154+0000] {subprocess.py:106} INFO - Try -help for more information
[2025-02-27T10:18:54.154+0000] {subprocess.py:106} INFO - Streaming Command Failed!
[2025-02-27T10:18:54.221+0000] {subprocess.py:110} INFO - Command exited with return code 1
[2025-02-27T10:18:54.231+0000] {taskinstance.py:3313} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 768, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 734, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 424, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 1.
[2025-02-27T10:18:54.239+0000] {taskinstance.py:1226} INFO - Marking task as UP_FOR_RETRY. dag_id=crypto, task_id=mapreduce, run_id=scheduled__2025-02-26T00:00:00+00:00, execution_date=20250226T000000, start_date=20250227T101853, end_date=20250227T101854
[2025-02-27T10:18:54.263+0000] {taskinstance.py:341} INFO - ::group::Post task execution logs
[2025-02-27T10:18:54.263+0000] {standard_task_runner.py:124} ERROR - Failed to execute job 84 for task mapreduce (Bash command failed. The command returned a non-zero exit code 1.; 306760)
Traceback (most recent call last):
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/task/task_runner/standard_task_runner.py", line 117, in _start_by_fork
    ret = args.func(args, dag=self.dag)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/cli/commands/task_command.py", line 483, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/cli/commands/task_command.py", line 256, in _run_task_by_selected_method
    return _run_raw_task(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/cli/commands/task_command.py", line 341, in _run_raw_task
    return ti._run_raw_task(
           ^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3006, in _run_raw_task
    return _run_raw_task(
           ^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 274, in _run_raw_task
    TaskInstance._execute_task_with_callbacks(
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3161, in _execute_task_with_callbacks
    result = self._execute_task(context, task_orig)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3185, in _execute_task
    return _execute_task(self, context, task_orig)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 768, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 734, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 424, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ali/Desktop/crypto/myenv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 1.
[2025-02-27T10:18:54.279+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 1
[2025-02-27T10:18:54.367+0000] {taskinstance.py:3901} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-02-27T10:18:54.367+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-02-27T11:06:53.015+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-02-27T11:06:53.025+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: crypto.mapreduce scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T11:06:53.030+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: crypto.mapreduce scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T11:06:53.030+0000] {taskinstance.py:2867} INFO - Starting attempt 1 of 2
[2025-02-27T11:06:53.038+0000] {taskinstance.py:2890} INFO - Executing <Task(BashOperator): mapreduce> on 2025-02-26 00:00:00+00:00
[2025-02-27T11:06:53.043+0000] {standard_task_runner.py:72} INFO - Started process 524375 to run task
[2025-02-27T11:06:53.045+0000] {standard_task_runner.py:104} INFO - Running: ['airflow', 'tasks', 'run', 'crypto', 'mapreduce', 'scheduled__2025-02-26T00:00:00+00:00', '--job-id', '88', '--raw', '--subdir', 'DAGS_FOLDER/crypto_dag.py', '--cfg-path', '/tmp/tmpysfvkkfe']
[2025-02-27T11:06:53.047+0000] {standard_task_runner.py:105} INFO - Job 88: Subtask mapreduce
[2025-02-27T11:06:53.069+0000] {task_command.py:467} INFO - Running <TaskInstance: crypto.mapreduce scheduled__2025-02-26T00:00:00+00:00 [running]> on host ali-ThinkBook-14-G2-ITL
[2025-02-27T11:06:53.188+0000] {taskinstance.py:3134} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='ali rahiqi' AIRFLOW_CTX_DAG_ID='crypto' AIRFLOW_CTX_TASK_ID='mapreduce' AIRFLOW_CTX_EXECUTION_DATE='2025-02-26T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-02-26T00:00:00+00:00'
[2025-02-27T11:06:53.189+0000] {taskinstance.py:732} INFO - ::endgroup::
[2025-02-27T11:06:53.197+0000] {subprocess.py:78} INFO - Tmp dir root location: /tmp
[2025-02-27T11:06:53.197+0000] {subprocess.py:88} INFO - Running command: ['/usr/bin/bash', '-c', 'hadoop jar /usr/local/hadoop/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar -D mapreduce.job.num.map.tasks=1 -input /user/etudiant/crypto/raw/YYYY=2025/MM=02/DD=27/coingecko_raw.json -output /user/etudiant/crypto/processed/YYYY=2025/MM=02/DD=27 -mapper "/usr/bin/env python3 /home/ali/Desktop/crypto/scripts/mapper.py" -reducer "/usr/bin/env python3 /home/ali/Desktop/crypto/scripts/reducer.py" -file /home/ali/Desktop/crypto/scripts/mapper.py -file /home/ali/Desktop/crypto/scripts/reducer.py']
[2025-02-27T11:06:53.204+0000] {subprocess.py:99} INFO - Output:
[2025-02-27T11:06:53.751+0000] {subprocess.py:106} INFO - 2025-02-27 11:06:53,751 WARN streaming.StreamJob: -file option is deprecated, please use generic option -files instead.
[2025-02-27T11:06:54.412+0000] {subprocess.py:106} INFO - packageJobJar: [/home/ali/Desktop/crypto/scripts/mapper.py, /home/ali/Desktop/crypto/scripts/reducer.py, /tmp/hadoop-unjar2310377645468606120/] [] /tmp/streamjob6055190270447806399.jar tmpDir=null
[2025-02-27T11:06:54.562+0000] {subprocess.py:106} INFO - 2025-02-27 11:06:54,562 INFO client.DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at /0.0.0.0:8032
[2025-02-27T11:06:54.734+0000] {subprocess.py:106} INFO - 2025-02-27 11:06:54,734 INFO client.DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at /0.0.0.0:8032
[2025-02-27T11:06:54.903+0000] {subprocess.py:106} INFO - 2025-02-27 11:06:54,903 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/ali/.staging/job_1740648251068_0013
[2025-02-27T11:06:55.141+0000] {subprocess.py:106} INFO - 2025-02-27 11:06:55,141 INFO mapred.FileInputFormat: Total input files to process : 1
[2025-02-27T11:06:55.174+0000] {subprocess.py:106} INFO - 2025-02-27 11:06:55,174 INFO mapreduce.JobSubmitter: number of splits:2
[2025-02-27T11:06:55.341+0000] {subprocess.py:106} INFO - 2025-02-27 11:06:55,341 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1740648251068_0013
[2025-02-27T11:06:55.341+0000] {subprocess.py:106} INFO - 2025-02-27 11:06:55,341 INFO mapreduce.JobSubmitter: Executing with tokens: []
[2025-02-27T11:06:55.495+0000] {subprocess.py:106} INFO - 2025-02-27 11:06:55,495 INFO conf.Configuration: resource-types.xml not found
[2025-02-27T11:06:55.495+0000] {subprocess.py:106} INFO - 2025-02-27 11:06:55,495 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.
[2025-02-27T11:06:55.533+0000] {subprocess.py:106} INFO - 2025-02-27 11:06:55,533 INFO impl.YarnClientImpl: Submitted application application_1740648251068_0013
[2025-02-27T11:06:55.557+0000] {subprocess.py:106} INFO - 2025-02-27 11:06:55,557 INFO mapreduce.Job: The url to track the job: http://ali-ThinkBook-14-G2-ITL:8088/proxy/application_1740648251068_0013/
[2025-02-27T11:06:55.557+0000] {subprocess.py:106} INFO - 2025-02-27 11:06:55,557 INFO mapreduce.Job: Running job: job_1740648251068_0013
[2025-02-27T11:07:00.644+0000] {subprocess.py:106} INFO - 2025-02-27 11:07:00,644 INFO mapreduce.Job: Job job_1740648251068_0013 running in uber mode : false
[2025-02-27T11:07:00.646+0000] {subprocess.py:106} INFO - 2025-02-27 11:07:00,646 INFO mapreduce.Job:  map 0% reduce 0%
[2025-02-27T11:07:06.711+0000] {subprocess.py:106} INFO - 2025-02-27 11:07:06,710 INFO mapreduce.Job:  map 100% reduce 0%
[2025-02-27T11:07:11.741+0000] {subprocess.py:106} INFO - 2025-02-27 11:07:11,741 INFO mapreduce.Job:  map 100% reduce 100%
[2025-02-27T11:07:11.754+0000] {subprocess.py:106} INFO - 2025-02-27 11:07:11,754 INFO mapreduce.Job: Job job_1740648251068_0013 completed successfully
[2025-02-27T11:07:11.828+0000] {subprocess.py:106} INFO - 2025-02-27 11:07:11,827 INFO mapreduce.Job: Counters: 54
[2025-02-27T11:07:11.828+0000] {subprocess.py:106} INFO - 	File System Counters
[2025-02-27T11:07:11.828+0000] {subprocess.py:106} INFO - 		FILE: Number of bytes read=15687
[2025-02-27T11:07:11.828+0000] {subprocess.py:106} INFO - 		FILE: Number of bytes written=872516
[2025-02-27T11:07:11.829+0000] {subprocess.py:106} INFO - 		FILE: Number of read operations=0
[2025-02-27T11:07:11.829+0000] {subprocess.py:106} INFO - 		FILE: Number of large read operations=0
[2025-02-27T11:07:11.829+0000] {subprocess.py:106} INFO - 		FILE: Number of write operations=0
[2025-02-27T11:07:11.829+0000] {subprocess.py:106} INFO - 		HDFS: Number of bytes read=33139
[2025-02-27T11:07:11.829+0000] {subprocess.py:106} INFO - 		HDFS: Number of bytes written=2205
[2025-02-27T11:07:11.830+0000] {subprocess.py:106} INFO - 		HDFS: Number of read operations=11
[2025-02-27T11:07:11.830+0000] {subprocess.py:106} INFO - 		HDFS: Number of large read operations=0
[2025-02-27T11:07:11.830+0000] {subprocess.py:106} INFO - 		HDFS: Number of write operations=2
[2025-02-27T11:07:11.830+0000] {subprocess.py:106} INFO - 		HDFS: Number of bytes read erasure-coded=0
[2025-02-27T11:07:11.830+0000] {subprocess.py:106} INFO - 	Job Counters
[2025-02-27T11:07:11.831+0000] {subprocess.py:106} INFO - 		Launched map tasks=2
[2025-02-27T11:07:11.831+0000] {subprocess.py:106} INFO - 		Launched reduce tasks=1
[2025-02-27T11:07:11.831+0000] {subprocess.py:106} INFO - 		Data-local map tasks=2
[2025-02-27T11:07:11.831+0000] {subprocess.py:106} INFO - 		Total time spent by all maps in occupied slots (ms)=6204
[2025-02-27T11:07:11.831+0000] {subprocess.py:106} INFO - 		Total time spent by all reduces in occupied slots (ms)=2278
[2025-02-27T11:07:11.832+0000] {subprocess.py:106} INFO - 		Total time spent by all map tasks (ms)=6204
[2025-02-27T11:07:11.832+0000] {subprocess.py:106} INFO - 		Total time spent by all reduce tasks (ms)=2278
[2025-02-27T11:07:11.832+0000] {subprocess.py:106} INFO - 		Total vcore-milliseconds taken by all map tasks=6204
[2025-02-27T11:07:11.832+0000] {subprocess.py:106} INFO - 		Total vcore-milliseconds taken by all reduce tasks=2278
[2025-02-27T11:07:11.833+0000] {subprocess.py:106} INFO - 		Total megabyte-milliseconds taken by all map tasks=6352896
[2025-02-27T11:07:11.833+0000] {subprocess.py:106} INFO - 		Total megabyte-milliseconds taken by all reduce tasks=2332672
[2025-02-27T11:07:11.833+0000] {subprocess.py:106} INFO - 	Map-Reduce Framework
[2025-02-27T11:07:11.833+0000] {subprocess.py:106} INFO - 		Map input records=1
[2025-02-27T11:07:11.833+0000] {subprocess.py:106} INFO - 		Map output records=276
[2025-02-27T11:07:11.834+0000] {subprocess.py:106} INFO - 		Map output bytes=15129
[2025-02-27T11:07:11.834+0000] {subprocess.py:106} INFO - 		Map output materialized bytes=15693
[2025-02-27T11:07:11.834+0000] {subprocess.py:106} INFO - 		Input split bytes=278
[2025-02-27T11:07:11.834+0000] {subprocess.py:106} INFO - 		Combine input records=0
[2025-02-27T11:07:11.834+0000] {subprocess.py:106} INFO - 		Combine output records=0
[2025-02-27T11:07:11.835+0000] {subprocess.py:106} INFO - 		Reduce input groups=23
[2025-02-27T11:07:11.835+0000] {subprocess.py:106} INFO - 		Reduce shuffle bytes=15693
[2025-02-27T11:07:11.835+0000] {subprocess.py:106} INFO - 		Reduce input records=276
[2025-02-27T11:07:11.835+0000] {subprocess.py:106} INFO - 		Reduce output records=23
[2025-02-27T11:07:11.835+0000] {subprocess.py:106} INFO - 		Spilled Records=552
[2025-02-27T11:07:11.836+0000] {subprocess.py:106} INFO - 		Shuffled Maps =2
[2025-02-27T11:07:11.836+0000] {subprocess.py:106} INFO - 		Failed Shuffles=0
[2025-02-27T11:07:11.836+0000] {subprocess.py:106} INFO - 		Merged Map outputs=2
[2025-02-27T11:07:11.836+0000] {subprocess.py:106} INFO - 		GC time elapsed (ms)=57
[2025-02-27T11:07:11.836+0000] {subprocess.py:106} INFO - 		CPU time spent (ms)=2110
[2025-02-27T11:07:11.837+0000] {subprocess.py:106} INFO - 		Physical memory (bytes) snapshot=907718656
[2025-02-27T11:07:11.837+0000] {subprocess.py:106} INFO - 		Virtual memory (bytes) snapshot=8252370944
[2025-02-27T11:07:11.837+0000] {subprocess.py:106} INFO - 		Total committed heap usage (bytes)=786432000
[2025-02-27T11:07:11.837+0000] {subprocess.py:106} INFO - 		Peak Map Physical memory (bytes)=327884800
[2025-02-27T11:07:11.837+0000] {subprocess.py:106} INFO - 		Peak Map Virtual memory (bytes)=2749120512
[2025-02-27T11:07:11.838+0000] {subprocess.py:106} INFO - 		Peak Reduce Physical memory (bytes)=253128704
[2025-02-27T11:07:11.838+0000] {subprocess.py:106} INFO - 		Peak Reduce Virtual memory (bytes)=2755334144
[2025-02-27T11:07:11.838+0000] {subprocess.py:106} INFO - 	Shuffle Errors
[2025-02-27T11:07:11.838+0000] {subprocess.py:106} INFO - 		BAD_ID=0
[2025-02-27T11:07:11.839+0000] {subprocess.py:106} INFO - 		CONNECTION=0
[2025-02-27T11:07:11.839+0000] {subprocess.py:106} INFO - 		IO_ERROR=0
[2025-02-27T11:07:11.839+0000] {subprocess.py:106} INFO - 		WRONG_LENGTH=0
[2025-02-27T11:07:11.839+0000] {subprocess.py:106} INFO - 		WRONG_MAP=0
[2025-02-27T11:07:11.839+0000] {subprocess.py:106} INFO - 		WRONG_REDUCE=0
[2025-02-27T11:07:11.840+0000] {subprocess.py:106} INFO - 	File Input Format Counters
[2025-02-27T11:07:11.840+0000] {subprocess.py:106} INFO - 		Bytes Read=32861
[2025-02-27T11:07:11.840+0000] {subprocess.py:106} INFO - 	File Output Format Counters
[2025-02-27T11:07:11.840+0000] {subprocess.py:106} INFO - 		Bytes Written=2205
[2025-02-27T11:07:11.840+0000] {subprocess.py:106} INFO - 2025-02-27 11:07:11,828 INFO streaming.StreamJob: Output directory: /user/etudiant/crypto/processed/YYYY=2025/MM=02/DD=27
[2025-02-27T11:07:12.187+0000] {subprocess.py:110} INFO - Command exited with return code 0
[2025-02-27T11:07:12.230+0000] {taskinstance.py:341} INFO - ::group::Post task execution logs
[2025-02-27T11:07:12.231+0000] {taskinstance.py:353} INFO - Marking task as SUCCESS. dag_id=crypto, task_id=mapreduce, run_id=scheduled__2025-02-26T00:00:00+00:00, execution_date=20250226T000000, start_date=20250227T110653, end_date=20250227T110712
[2025-02-27T11:07:12.282+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-02-27T11:07:12.365+0000] {taskinstance.py:3901} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-02-27T11:07:12.366+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
